{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2770094e-bede-4ba4-8bda-57dcdd9143a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get articles from elastic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e83f44-c5f3-439f-ae3a-270f7a8b01fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5548cd48-cc77-4a90-9998-99ac172a6567",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch([{'host':'localhost', 'port':9200}], http_auth=('uchicago', '3fMy7Wq90LDWBCMEXt6j'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df2c225-29c0-4e41-a69d-73c97b031e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = es.search(\n",
    "    index='emm_data', \n",
    "    size=5000, \n",
    "    body={'query':{'match_all':{}}}, \n",
    "    _source=['source', 'link']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22830d65-a518-4ffb-8732-1c6bd77cf82d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b019e77-ba8f-46e0-a16a-d4a952879c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# store article's id and url in json\n",
    "def get_id_and_url(res):\n",
    "    results = res['hits']['hits']\n",
    "    res_dict = {}\n",
    "    for r in results:\n",
    "        # get result id and url\n",
    "        res_id = r['_id']\n",
    "        res_url = r['_source']['link']\n",
    "        \n",
    "        # store the values in a dictionary\n",
    "        res_dict[res_id] = res_url    \n",
    "#     j = json.dumps(res_dict)\n",
    "    # save info to a json file\n",
    "    with open('data.json', 'w') as f:\n",
    "        json.dump(res_dict, f)\n",
    "\n",
    "get_id_and_url(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da7830b-1713-42a1-8c0c-77a82c6ba0b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0404d2-53f7-404b-9869-e01b087f823b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get and return a list of urls\n",
    "def get_urls():\n",
    "    results = res['hits']['hits']\n",
    "    urls = {}\n",
    "    for u in results:\n",
    "        url_id = u['_id']\n",
    "        url = u['_source']['link']\n",
    "        urls[url_id] = url\n",
    "    return urls\n",
    "    \n",
    "# len(get_urls())\n",
    "get_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16ca3ff-9e77-4aac-b9ec-ec54aa91d388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f120de2-268d-430b-bc45-a46e63c40798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37d6bad-2b62-47a3-9a5c-0e7c3a74e429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d7da02-b78e-4a0f-86af-213444904933",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78be52e2-a691-4710-8d3b-0c05d46df939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting information from the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd5183e-a9a0-41be-970d-d6ac63310a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import newspaper\n",
    "from newspaper import Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb87c07-1a9e-4ef8-aa5d-2fbcb4215128",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get article's url\n",
    "url = res['hits']['hits'][0].get('_source')['link']\n",
    "\n",
    "# create Article object\n",
    "article = Article(url)\n",
    "\n",
    "# download & parse the article\n",
    "article.download()\n",
    "article.parse()\n",
    "\n",
    "# extract NL properties from the text\n",
    "article.nlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6db0a0c-8f26-4552-881d-cccab3d9e086",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get author(s), publish date & top image\n",
    "f'author: {article.authors},    publication date: {article.publish_date},    top image: {article.top_image}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12bfc0d-2da6-4653-aa27-8b7f7ae819e2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the article's text\n",
    "article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9099002f-5789-4457-afd2-613ff8e44669",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now perform NLP on the article's text with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b313ff2-ae30-4bcd-b5a3-ae1f90102381",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4ee901-de1b-4774-ae2c-f82bcd828dd1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939069f8-9770-4a28-9408-3390dea58227",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# store the article's text\n",
    "article_text = article.text\n",
    "\n",
    "# tokenize the text\n",
    "article_doc = nlp(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18615f05-66df-44b2-85f8-7e541235fef8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract tokens from the doc\n",
    "article_tokens = [token.text for token in article_doc]\n",
    "\n",
    "# print the tokens\n",
    "article_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a64ec46-5a49-4fe8-a990-c1e14c352969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aba378b-88e1-419f-b54a-2ed5d45ad773",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract info and perfom NLP on articles\n",
    "def extract_article_info():\n",
    "    articles_dict = {}\n",
    "#     for i in range(5):\n",
    "    for url_id, url in get_urls().items()[:5]:\n",
    "        # create Article object\n",
    "        article = Article(url)\n",
    "\n",
    "        # check for valid url\n",
    "#             if article.is_valid_url():\n",
    "        try:\n",
    "            # download and parse the article\n",
    "            article.download()\n",
    "            article.parse()\n",
    "            # extract NL properties from article's text\n",
    "            article.nlp()\n",
    "            # store article's text\n",
    "            articles_dict[url_id] = article.text\n",
    "#                 print(f'{url_id} : {article.text}')\n",
    "        except:\n",
    "            print('could not download article')\n",
    "    return articles_dict\n",
    "\n",
    "# articles_dict = extract_article_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d18232-053d-497b-b026-c8acedca4258",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extract_article_info().items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67094fb-542e-4a91-95d8-62c5e9283d2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "import numpy as np\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef3c14a-016a-4424-9766-f97e6aae8b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')\n",
    "\n",
    "articles_attr = {}\n",
    "subjectivity_vals = np.empty(shape=[0, 1])\n",
    "polarity_vals = np.empty(shape=[0, 1])\n",
    "id_legend = np.empty(shape=[0, 1])\n",
    "\n",
    "for key, value in articles_dict.items():\n",
    "    doc = nlp(each)\n",
    "    articles_attr[key] = [doc._.polarity, doc._.subjectivity, doc._.assessments]\n",
    "    np.append(subjectivity_vals, doc._.subjectivity)\n",
    "    np.append(polarity_vals, doc._.polarity)\n",
    "    np.append(id_legend, key)\n",
    "\n",
    "#subjectivity: 0.0 = objective, 1.0 = subjective\n",
    "#polarity: measures level of approval/disapproval\n",
    "#assessments = list of polarity, subjectivity scores for assessed tokens\n",
    "\n",
    "\n",
    "#x-y plot of subjectivity, polarity\n",
    "#see if there is any relationship, clustering\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def do_plot(subjectivity_vals, polarity_vals, tags):\n",
    "    # Plot\n",
    "    plt.plot(subjectivtity_vals, polarity_vals, label=\"oridinal data\")\n",
    "    plt.xlabel(\"Subjectivity\")\n",
    "    plt.ylabel(\"Polarity\")\n",
    "    plt.title(\"Subjectivity-Polarity Word-level\")\n",
    "    plt.legend()\n",
    "    m, b = np.polyfit(x, y, 1) #regression\n",
    "    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(x, y)\n",
    "    plt.plot(x, m*x + b)\n",
    "    plt.savefig(\"initial_plot.png\")\n",
    "    plt.close()\n",
    "\n",
    "do_plot(subjectivity_vals, polarity_vals, id_legend)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03289c06-bba9-49d6-9fa3-62172b40ce6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}